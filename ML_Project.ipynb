{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "-N1taHGUqTyT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SEgLah6nnOBH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data_dir = '/content/drive/MyDrive/ML Project Data Set/training_set'\n",
        "test_data_dir = '/content/drive/MyDrive/ML Project Data Set/test_set'\n",
        "categories = ['Agreeableness', 'Conscientiousness', 'Extraversion', 'Neuroticism', 'Openness']\n"
      ],
      "metadata": {
        "id": "IJOQ0QlLqA7s"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    image = cv2.resize(image, (128, 128))  # Resize to 128x128\n",
        "    image = image / 255.0  # Normalize pixel values\n",
        "    return image\n",
        "\n"
      ],
      "metadata": {
        "id": "A9GqasT5qDVL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for idx, category in enumerate(categories):\n",
        "        category_path = os.path.join(data_dir, category)\n",
        "        for img_name in os.listdir(category_path):\n",
        "            img_path = os.path.join(category_path, img_name)\n",
        "            image = preprocess_image(img_path)\n",
        "            images.append(image)\n",
        "            labels.append(idx)\n",
        "    return np.array(images), np.array(labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "V951euA1qFT7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_images, train_labels = load_data(train_data_dir)\n",
        "\n",
        "test_images, test_labels = load_data(test_data_dir)\n",
        "\n"
      ],
      "metadata": {
        "id": "hPMHDBX9qH9L"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_images = np.expand_dims(train_images, axis=-1)  # Add channel dimension\n",
        "test_images = np.expand_dims(test_images, axis=-1)\n",
        "train_labels = to_categorical(train_labels, num_classes=len(categories))  # One-hot encoding\n",
        "test_labels = to_categorical(test_labels, num_classes=len(categories))\n"
      ],
      "metadata": {
        "id": "p0IJXW8nqKAi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Trainig**"
      ],
      "metadata": {
        "id": "1HqXK_EBqObT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 1)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(len(categories), activation='softmax')  # Multi-class classification\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "\n"
      ],
      "metadata": {
        "id": "fAVeJIe2qN0S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.fit(train_images, train_labels, epochs=25, validation_data=(test_images, test_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q66eCWL7q4BZ",
        "outputId": "afb812b8-feef-4735-b6b7-3eadb40611f4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "6/6 [==============================] - 6s 1s/step - loss: 1.1554 - accuracy: 0.5311 - val_loss: 1.4304 - val_accuracy: 0.4091\n",
            "Epoch 2/25\n",
            "6/6 [==============================] - 5s 737ms/step - loss: 1.0000 - accuracy: 0.6102 - val_loss: 1.4303 - val_accuracy: 0.5000\n",
            "Epoch 3/25\n",
            "6/6 [==============================] - 4s 707ms/step - loss: 0.8998 - accuracy: 0.6102 - val_loss: 1.5612 - val_accuracy: 0.3182\n",
            "Epoch 4/25\n",
            "6/6 [==============================] - 6s 976ms/step - loss: 0.8245 - accuracy: 0.7119 - val_loss: 1.6873 - val_accuracy: 0.4545\n",
            "Epoch 5/25\n",
            "6/6 [==============================] - 5s 793ms/step - loss: 0.6234 - accuracy: 0.8362 - val_loss: 1.7733 - val_accuracy: 0.4545\n",
            "Epoch 6/25\n",
            "6/6 [==============================] - 4s 721ms/step - loss: 0.4397 - accuracy: 0.9040 - val_loss: 1.8618 - val_accuracy: 0.3636\n",
            "Epoch 7/25\n",
            "6/6 [==============================] - 5s 881ms/step - loss: 0.3441 - accuracy: 0.9322 - val_loss: 1.9573 - val_accuracy: 0.3636\n",
            "Epoch 8/25\n",
            "6/6 [==============================] - 6s 990ms/step - loss: 0.2511 - accuracy: 0.9774 - val_loss: 2.0630 - val_accuracy: 0.4091\n",
            "Epoch 9/25\n",
            "6/6 [==============================] - 5s 781ms/step - loss: 0.1828 - accuracy: 0.9831 - val_loss: 2.2626 - val_accuracy: 0.4318\n",
            "Epoch 10/25\n",
            "6/6 [==============================] - 6s 955ms/step - loss: 0.1271 - accuracy: 0.9887 - val_loss: 2.5568 - val_accuracy: 0.4091\n",
            "Epoch 11/25\n",
            "6/6 [==============================] - 6s 1s/step - loss: 0.0911 - accuracy: 0.9944 - val_loss: 2.3589 - val_accuracy: 0.3636\n",
            "Epoch 12/25\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 2.8482 - val_accuracy: 0.4318\n",
            "Epoch 13/25\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 2.5531 - val_accuracy: 0.3636\n",
            "Epoch 14/25\n",
            "6/6 [==============================] - 5s 799ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 3.2029 - val_accuracy: 0.4318\n",
            "Epoch 15/25\n",
            "6/6 [==============================] - 4s 742ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 2.7426 - val_accuracy: 0.3864\n",
            "Epoch 16/25\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 3.2651 - val_accuracy: 0.4318\n",
            "Epoch 17/25\n",
            "6/6 [==============================] - 5s 772ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 3.0004 - val_accuracy: 0.3864\n",
            "Epoch 18/25\n",
            "6/6 [==============================] - 5s 748ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 3.1594 - val_accuracy: 0.4318\n",
            "Epoch 19/25\n",
            "6/6 [==============================] - 7s 1s/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 3.3760 - val_accuracy: 0.4318\n",
            "Epoch 20/25\n",
            "6/6 [==============================] - 4s 665ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 3.2072 - val_accuracy: 0.3864\n",
            "Epoch 21/25\n",
            "6/6 [==============================] - 4s 706ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 3.4344 - val_accuracy: 0.4318\n",
            "Epoch 22/25\n",
            "6/6 [==============================] - 6s 960ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.3542 - val_accuracy: 0.4318\n",
            "Epoch 23/25\n",
            "6/6 [==============================] - 5s 774ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 3.4193 - val_accuracy: 0.4318\n",
            "Epoch 24/25\n",
            "6/6 [==============================] - 4s 739ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 3.4946 - val_accuracy: 0.4318\n",
            "Epoch 25/25\n",
            "6/6 [==============================] - 6s 967ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 3.4985 - val_accuracy: 0.4318\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fc62c5cd300>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Evaluation**"
      ],
      "metadata": {
        "id": "Kob5KwVzqZrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "loss, accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2Sl6gugqewl",
        "outputId": "984942cd-bbb8-48df-a6b8-6cef3a125c63"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 76ms/step - loss: 3.4985 - accuracy: 0.4318\n",
            "Test Accuracy: 43.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction**"
      ],
      "metadata": {
        "id": "1C1T1L3OqfFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_personality(image_path):\n",
        "    image = preprocess_image(image_path)\n",
        "    image = np.expand_dims(image, axis=-1)  # Expand dims to match input shape\n",
        "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "    prediction = model.predict(image)\n",
        "    predicted_label = np.argmax(prediction, axis=1)[0]\n",
        "    return categories[predicted_label]\n",
        "\n",
        "\n",
        "new_image_path = '/content/drive/MyDrive/Sacrificial Lambs/160122124623-01-national-handwriting-day.jpg'\n",
        "print(predict_personality(new_image_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZuPdNNcqkva",
        "outputId": "097b8d9a-e491-41d5-c456-5fb6946e51b4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 381ms/step\n",
            "Openness\n"
          ]
        }
      ]
    }
  ]
}